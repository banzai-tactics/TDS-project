{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from helpers import utils, pipelines, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, SMOTENC, ADASYN\n",
    "\n",
    "import dice_ml\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from collections.abc import Iterable\n",
    "from functools import partial\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define research parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'f1'#roc_auc#f1#accuracy\n",
    "\n",
    "test_size_proportion=0.33\n",
    "\n",
    "sample_frac = 0.05\n",
    "\n",
    "search_pipelines = pipelines.get_classification_pipelines()\n",
    "search_parameters = models.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(r\"datasets\\german_credit.csv\", index_col=0)\n",
    "df = utils.preprocess_german(raw_data)\n",
    "target = 'Risk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_proportion, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    471\n",
       "0    199\n",
       "Name: Risk, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole dataset scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole adult dataset f1 scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full data f1 score</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.822669</td>\n",
       "      <td>0.815109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          lg        rf       xgb\n",
       "full data f1 score  0.823529  0.822669  0.815109"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'whole adult dataset {scoring} scores:')\n",
    "whole_best_ests, whole_scores = utils.fit_and_evaluate(X_train, y_train, X_test, y_test,\n",
    "                    search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "whole_dataset_result_df = pd.DataFrame.from_dict(whole_scores, orient='index', columns=[f'full data {scoring} score'])\n",
    "whole_dataset_result_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random over sampling (all classes but the majority class until balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    471\n",
       "0    471\n",
       "Name: Risk, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0% sampled adult dataset with Random Over Sampling f1 scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROS f1 score</th>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.775414</td>\n",
       "      <td>0.788546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    lg        rf       xgb\n",
       "ROS f1 score  0.759259  0.775414  0.788546"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42) # resample all classes but the majority class\n",
    "X_resampled_ros, y_resampled_ros = ros.fit_resample(X_train, y_train)\n",
    "display(y_resampled_ros.value_counts())\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with Random Over Sampling {scoring} scores:')\n",
    "\n",
    "_, sampled_scores = utils.fit_and_evaluate(X_resampled_ros, y_resampled_ros, X_test, y_test,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "ros_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'ROS {scoring} score'])\n",
    "ros_result_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE & ADASYN (all classes but the majority class until balanced)\n",
    "working just on numerical so need to transform before, so we insert it to the pipeline after the preproccess step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('categorical', pipelines.categorical_pipe, make_column_selector(dtype_include=['object'])),\n",
    "], remainder='passthrough')\n",
    "\n",
    "preprocess_X_train = ct.fit_transform(X_train)\n",
    "preprocess_X_test = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add to pipeline\n",
    "# smote_pipelines = deepcopy(search_pipelines)\n",
    "# for n, p in smote_pipelines.items():\n",
    "#     p.steps.insert(1, ('smote', SMOTE(random_state=42)))\n",
    "\n",
    "\n",
    "# print(f'{sample_frac*100}% sampled adult dataset with SMOTE {scoring} scores:')\n",
    "# _, sampled_scores = utils.fit_and_evaluate(X_sample_train, y_sample_train, X_sample_test, y_sample_test,\n",
    "#                         search_estimators=smote_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "# smote_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'SMOTE {scoring} score'])\n",
    "# smote_result_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    471\n",
       "0    471\n",
       "Name: Risk, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0% sampled adult dataset with SMOTE f1 scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SMOTE f1 score</th>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.786957</td>\n",
       "      <td>0.816327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      lg        rf       xgb\n",
       "SMOTE f1 score  0.763889  0.786957  0.816327"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42) # resample all classes but the majority class\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(pd.DataFrame(preprocess_X_train), y_train)\n",
    "display(y_resampled_smote.value_counts())\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with SMOTE {scoring} scores:')\n",
    "smote_best_ests, sampled_scores = utils.fit_and_evaluate(X_resampled_smote, y_resampled_smote, preprocess_X_test, y_test,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "smote_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'SMOTE {scoring} score'])\n",
    "smote_result_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    471\n",
       "0    471\n",
       "Name: Risk, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0% sampled adult dataset with SMOTENC f1 scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SMOTENC f1 score</th>\n",
       "      <td>0.785219</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>0.812362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        lg        rf       xgb\n",
       "SMOTENC f1 score  0.785219  0.791946  0.812362"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTENC(random_state=42, categorical_features=['Sex', 'Job', 'Housing', 'Saving accounts', 'Checking account', 'Purpose']) # resample all classes but the majority class\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_train, y_train)\n",
    "display(y_resampled_smote.value_counts())\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with SMOTENC {scoring} scores:')\n",
    "smote_best_ests, sampled_scores = utils.fit_and_evaluate(X_resampled_smote, y_resampled_smote, X_test, y_test,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "smote_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'SMOTENC {scoring} score'])\n",
    "smote_result_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 706, 0: 298}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    706\n",
       "0    298\n",
       "Name: Risk, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0% sampled adult dataset with SMOTENC f1 scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SMOTENC f1 score</th>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.819853</td>\n",
       "      <td>0.817427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        lg        rf       xgb\n",
       "SMOTENC f1 score  0.819277  0.819853  0.817427"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_samples = ((y_train.value_counts(normalize=True))*(len(y_train)*0.5)).astype(int)\n",
    "sample_strategy = (additional_samples + y_train.value_counts()).to_dict()\n",
    "sampler = SMOTENC(random_state=42, categorical_features=['Sex', 'Job', 'Housing', 'Saving accounts', 'Checking account', 'Purpose'],\n",
    "                    sampling_strategy=sample_strategy)\n",
    "\n",
    "X_resampled_smote, y_resampled_smote = sampler.fit_resample(X_train, y_train)\n",
    "display(y_resampled_smote.value_counts())\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with SMOTENC {scoring} scores:')\n",
    "smote_best_ests, sampled_scores = utils.fit_and_evaluate(X_resampled_smote, y_resampled_smote, X_test, y_test,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "smote_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'SMOTENC {scoring} score'])\n",
    "smote_result_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0% sampled adult dataset with ADASYN f1 scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADASYN f1 score</th>\n",
       "      <td>0.76815</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.813142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      lg        rf       xgb\n",
       "ADASYN f1 score  0.76815  0.785714  0.813142"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adasyn = ADASYN(random_state=42) # resample all classes but the majority class\n",
    "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(pd.DataFrame(preprocess_X_train), y_train) #X_sample\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with ADASYN {scoring} scores:')\n",
    "_, sampled_scores = utils.fit_and_evaluate(X_resampled_adasyn, y_resampled_adasyn, preprocess_X_test, y_test,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "adasyn_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'ADASYN {scoring} score'])\n",
    "adasyn_result_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter Factuals\n",
    "\n",
    "need to test many variables (differents generation methods / proximity vs diversity / balancing data / etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sampled data f1 score</th>\n",
       "      <td>0.829175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            knn\n",
       "sampled data f1 score  0.829175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# svc_pipeline = {'svc': Pipeline([('column_transformer', pipelines.preprocessor),('model', SVC(random_state=42))])}\n",
    "# svc_params = {'svc': {'model__C': [0.5, 1, 5], 'model__kernel': ['linear', 'rbf'], 'model__gamma': ['scale', 'auto']}}\n",
    "# best_svc_estimator, sampled_scores = utils.fit_and_evaluate(X_sample, y_sample,\n",
    "#                         search_estimators=svc_pipeline, search_params=svc_params, scoring=scoring)\n",
    "# pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'sampled data {scoring} score']).T\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# gbm_pipeline = {'gbm': Pipeline([('column_transformer', pipelines.preprocessor),('model', LGBMClassifier(random_state=42, verbose=-1))])}\n",
    "# gbm_params = {'gbm': {\n",
    "#     'model__max_depth': [5, 6, 7], \n",
    "#                       'model__min_child_samples': [30, 50], \n",
    "#                         'model__num_leaves': [25, 55], \n",
    "#                         'model__learning_rate': [0.1, 0.3, 0.5],\n",
    "#                         'model__reg_lambda': [0, 0.5, 1.5, 3],\n",
    "#                         }}\n",
    "# best_gbm_estimator, sampled_scores = utils.fit_and_evaluate(X_train, y_train, X_test, y_test,\n",
    "#                         search_estimators=gbm_pipeline, search_params=gbm_params, scoring=scoring)\n",
    "# pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'sampled data {scoring} score']).T\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn_pipeline = {'knn': Pipeline([('column_transformer', pipelines.preprocessor),('model', KNeighborsClassifier())])}\n",
    "knn_params = {'knn': {'model__n_neighbors': list(range(1,21)), 'model__weights': ['uniform', 'distance'],\n",
    "                      'model__p': [1,2], 'model__algorithm': ['ball_tree', 'kd_tree', 'brute'],}}\n",
    "best_cf_estimator, sampled_scores = utils.fit_and_evaluate(X_train, y_train, X_test, y_test,\n",
    "                        search_estimators=knn_pipeline, search_params=knn_params, scoring=scoring)\n",
    "pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'sampled data {scoring} score']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'ball_tree',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 19,\n",
       " 'p': 1,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cf_estimator['knn']['model'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=df, continuous_features=['Age', 'Credit amount', 'Duration'], outcome_name=target)\n",
    "m = dice_ml.Model(model=best_cf_estimator['knn'], backend=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n"
     ]
    }
   ],
   "source": [
    "exp = dice_ml.Dice(d, m, method=\"random\") # need to check diferent method (random, genetic, kdtree)\n",
    "\n",
    "minority_class = y_train.value_counts().idxmin()\n",
    "majority_class = y_train.value_counts().idxmax()\n",
    "classes_gap = y_train.value_counts()[majority_class]-y_train.value_counts()[minority_class]\n",
    "\n",
    "# X_sample_minority_class = df_sample[df_sample[target] == minority_class].drop(target, axis=1)\n",
    "X_sample_majority_class = X_train[y_train == majority_class]\n",
    "\n",
    "augmented_data = pd.DataFrame()\n",
    "cf_per = 1\n",
    "cf_counter = 0\n",
    "for i, (index, row) in enumerate(X_sample_majority_class.iterrows()):\n",
    "    if cf_counter >= classes_gap: break\n",
    "    if i%500 == 0: print(f'{i}/{classes_gap}')\n",
    "    try:\n",
    "        e1 = exp.generate_counterfactuals(pd.DataFrame(row).T, total_CFs=cf_per, desired_class=\"opposite\",\n",
    "                                          verbose=False,\n",
    "                                        #   proximity_weight=1, diversity_weight=0\n",
    "                                          )#, verbose=False)\n",
    "        cf_df = e1.cf_examples_list[0].final_cfs_df\n",
    "        if cf_df[target].iloc[0]!=minority_class: continue\n",
    "        augmented_data = pd.concat([augmented_data, cf_df])\n",
    "        cf_counter += len(cf_df)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    471\n",
       "0    471\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0% sampled adult dataset with CF f1 scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CF f1 score</th>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lg        rf       xgb\n",
       "CF f1 score  0.802632  0.768519  0.809524"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_augmented_cf = pd.concat([X_train, augmented_data.drop(target, axis=1)]).astype(X_train.dtypes)\n",
    "y_augmented_cf = pd.concat([y_train, pd.Series([minority_class]*len(augmented_data))])\n",
    "\n",
    "display(y_augmented_cf.value_counts())\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with CF {scoring} scores:')\n",
    "best_est_cf_random, sampled_scores = utils.fit_and_evaluate(X_augmented_cf, y_augmented_cf, X_test, y_test,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "cf_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'CF {scoring} score'])\n",
    "cf_result_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full data f1 score</th>\n",
       "      <th>ROS f1 score</th>\n",
       "      <th>SMOTE f1 score</th>\n",
       "      <th>ADASYN f1 score</th>\n",
       "      <th>CF f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lg</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.768150</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.822669</td>\n",
       "      <td>0.775414</td>\n",
       "      <td>0.786957</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.768519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.815109</td>\n",
       "      <td>0.788546</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.813142</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     full data f1 score  ROS f1 score  SMOTE f1 score  ADASYN f1 score  \\\n",
       "lg             0.823529      0.759259        0.763889         0.768150   \n",
       "rf             0.822669      0.775414        0.786957         0.785714   \n",
       "xgb            0.815109      0.788546        0.816327         0.813142   \n",
       "\n",
       "     CF f1 score  \n",
       "lg      0.802632  \n",
       "rf      0.768519  \n",
       "xgb     0.809524  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.concat([whole_dataset_result_df, ros_result_df, smote_result_df, adasyn_result_df, cf_result_df], axis=1)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(rf'log/german_{scoring}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est_cf_random['xgb']['model'].get_params()['reg_lambda']\n",
    "smote_best_ests['xgb']['model'].get_params()['reg_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
