{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from helpers import utils, pipelines, models\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "\n",
    "import dice_ml\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from collections.abc import Iterable\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUGMENTATION ONLY ON TRAIN SET! NEED TO FIX!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"./datasets/adult.csv\")\n",
    "df = utils.preprocess_adult(raw_data)\n",
    "target = 'income'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define research parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'#roc_auc#f1\n",
    "\n",
    "search_pipelines = pipelines.get_adult_pipelines()\n",
    "search_parameters = models.parameters\n",
    "\n",
    "sample_frac = 0.2\n",
    "df_sample = df.sample(frac=sample_frac, random_state=42)\n",
    "X_sample = df_sample.drop(target, axis=1)\n",
    "y_sample = df_sample[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole adult dataset scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole adult dataset accuracy scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full data accuracy score</th>\n",
       "      <td>0.828951</td>\n",
       "      <td>0.824591</td>\n",
       "      <td>0.832372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                lg        rf       xgb\n",
       "full data accuracy score  0.828951  0.824591  0.832372"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'whole adult dataset {scoring} scores:')\n",
    "_, whole_scores = utils.fit_and_evaluate(X, y,\n",
    "                    search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "whole_dataset_result_df = pd.DataFrame.from_dict(whole_scores, orient='index', columns=[f'full data {scoring} score'])\n",
    "whole_dataset_result_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampled adult dataset scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0% sampled adult dataset accuracy scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sampled data accuracy score</th>\n",
       "      <td>0.815225</td>\n",
       "      <td>0.812542</td>\n",
       "      <td>0.813548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   lg        rf       xgb\n",
       "sampled data accuracy score  0.815225  0.812542  0.813548"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{sample_frac*100}% sampled adult dataset {scoring} scores:')\n",
    "_, sampled_scores = utils.fit_and_evaluate(X_sample, y_sample,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "sampled_dataset_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'sampled data {scoring} score'])\n",
    "sampled_dataset_result_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random over sampling (all classes but the majority class until balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42) # resample all classes but the majority class\n",
    "X_resampled_ros, y_resampled_ros = ros.fit_resample(X_sample, y_sample)\n",
    "display(y_resampled_ros.value_counts())\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with Random Over Sampling {scoring} scores:')\n",
    "_, sampled_scores = utils.fit_and_evaluate(X_resampled_ros, y_resampled_ros,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "ros_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'ROS {scoring} score'])\n",
    "ros_result_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE & ADASYN (all classes but the majority class until balanced)\n",
    "working just on numerical so need to transform before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('categorical', pipelines.categorical_pipe, make_column_selector(dtype_include=['object'])),\n",
    "], remainder='passthrough')\n",
    "\n",
    "preprocess_X_sample = ct.fit_transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42) # resample all classes but the majority class\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(pd.DataFrame(preprocess_X_sample), y_sample) #X_sample\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with SMOTE {scoring} scores:')\n",
    "_, sampled_scores = utils.fit_and_evaluate(X_resampled_smote, y_resampled_smote,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "smote_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'SMOTE {scoring} score'])\n",
    "smote_result_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN(random_state=42) # resample all classes but the majority class\n",
    "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(pd.DataFrame(preprocess_X_sample), y_sample) #X_sample\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with ADASYN {scoring} scores:')\n",
    "_, sampled_scores = utils.fit_and_evaluate(X_resampled_adasyn, y_resampled_adasyn,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "adasyn_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'ADASYN {scoring} score'])\n",
    "adasyn_result_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter Factuals\n",
    "\n",
    "need to test many variables (differents generation methods / proximity vs diversity / balancing data / etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# svc_pipeline = {'svc': Pipeline([('column_transformer', pipelines.preprocessor),('model', SVC(random_state=42))])}\n",
    "# svc_params = {'svc': {'model__C': [0.5, 1, 5], 'model__kernel': ['linear', 'rbf'], 'model__gamma': ['scale', 'auto']}}\n",
    "# best_svc_estimator, sampled_scores = utils.fit_and_evaluate(X_sample, y_sample,\n",
    "#                         search_estimators=svc_pipeline, search_params=svc_params, scoring=scoring)\n",
    "# pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'sampled data {scoring} score']).T\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "gbm_pipeline = {'gbm': Pipeline([('column_transformer', pipelines.preprocessor),('model', LGBMClassifier(random_state=42, verbose=-1))])}\n",
    "gbm_params = {'gbm': {'model__max_depth': [5, 6, 7], 'model__min_child_weight': [30, 50], \n",
    "                        'model__num_leaves': [25, 55, 80]}}\n",
    "best_gbm_estimator, sampled_scores = utils.fit_and_evaluate(X_sample, y_sample,\n",
    "                        search_estimators=gbm_pipeline, search_params=gbm_params, scoring=scoring)\n",
    "pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'sampled data {scoring} score']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=df_sample, continuous_features=['age', 'fnlwgt', 'hours-per-week'], outcome_name=target)\n",
    "m = dice_ml.Model(model=best_gbm_estimator['gbm'], backend=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "exp = dice_ml.Dice(d, m, method=\"random\") # need to check diferent method\n",
    "\n",
    "minority_class = y_sample.value_counts().idxmin()\n",
    "majority_class = y_sample.value_counts().idxmax()\n",
    "classes_gap = y_sample.value_counts()[majority_class]-y_sample.value_counts()[minority_class]\n",
    "\n",
    "# X_sample_minority_class = df_sample[df_sample[target] == minority_class].drop(target, axis=1)\n",
    "X_sample_majority_class = df_sample[df_sample[target] == majority_class].drop(target, axis=1)\n",
    "\n",
    "augmented_data = pd.DataFrame()\n",
    "cf_per = 1\n",
    "cf_counter = 0\n",
    "for i, (index, row) in enumerate(X_sample_majority_class.iterrows()):\n",
    "    if cf_counter >= classes_gap: break\n",
    "    if i%500 == 0: print(f'{i}/{classes_gap}')\n",
    "    try:\n",
    "        e1 = exp.generate_counterfactuals(pd.DataFrame(row).T, total_CFs=cf_per, desired_class=\"opposite\")#, verbose=False)\n",
    "        cf_df = e1.cf_examples_list[0].final_cfs_df\n",
    "        if cf_df[target].iloc[0]!=minority_class: continue\n",
    "        augmented_data = pd.concat([augmented_data, cf_df])\n",
    "        cf_counter += len(cf_df)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf_augmented_df = pd.concat([df_sample, augmented_data])\n",
    "# X_augmented_cf = cf_augmented_df.drop(target, axis=1)\n",
    "# y_augmented_cf = cf_augmented_df[target]\n",
    "\n",
    "X_augmented_cf = pd.concat([X_sample, augmented_data.drop(target, axis=1)])\n",
    "y_augmented_cf = pd.concat([y_sample, pd.Series([minority_class]*len(augmented_data))])\n",
    "\n",
    "# classes_gap = y_sample.value_counts()[majority_class]-y_sample.value_counts()[minority_class]\n",
    "# fix_augmented_data = augmented_data[augmented_data[target]==minority_class].sample(classes_gap)\n",
    "# X_augmented_cf = pd.concat([X_sample, fix_augmented_data.drop(target, axis=1)])\n",
    "# y_augmented_cf = pd.concat([y_sample, pd.Series([minority_class]*len(fix_augmented_data))])\n",
    "\n",
    "display(y_augmented_cf.value_counts())\n",
    "\n",
    "print(f'{sample_frac*100}% sampled adult dataset with CF {scoring} scores:')\n",
    "best_est_cf_random, sampled_scores = utils.fit_and_evaluate(X_augmented_cf, y_augmented_cf,\n",
    "                        search_estimators=search_pipelines, search_params=search_parameters, scoring=scoring)\n",
    "cf_result_df = pd.DataFrame.from_dict(sampled_scores, orient='index', columns=[f'CF {scoring} score'])\n",
    "cf_result_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([whole_dataset_result_df, sampled_dataset_result_df, ros_result_df, smote_result_df, adasyn_result_df, cf_result_df], axis=1)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(rf'log/adult_{scoring}_{str(int(sample_frac*100))}%.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
